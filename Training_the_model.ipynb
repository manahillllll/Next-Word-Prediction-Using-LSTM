{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a15391-8394-492b-8404-b4560f940f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bb7002-3a90-48ca-bc5a-916bc6fcda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    1/12831\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:17:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 10.1495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 74ms/step - accuracy: 0.0582 - loss: 6.7359\n",
      "Epoch 2/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m959s\u001b[0m 75ms/step - accuracy: 0.1080 - loss: 5.8738\n",
      "Epoch 3/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 76ms/step - accuracy: 0.1211 - loss: 5.6106\n",
      "Epoch 4/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1139s\u001b[0m 89ms/step - accuracy: 0.1316 - loss: 5.4011\n",
      "Epoch 5/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1030s\u001b[0m 80ms/step - accuracy: 0.1420 - loss: 5.2195\n",
      "Epoch 6/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1055s\u001b[0m 82ms/step - accuracy: 0.1517 - loss: 5.0651\n",
      "Epoch 7/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1073s\u001b[0m 84ms/step - accuracy: 0.1638 - loss: 4.9019\n",
      "Epoch 8/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 85ms/step - accuracy: 0.1758 - loss: 4.7663\n",
      "Epoch 9/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1100s\u001b[0m 86ms/step - accuracy: 0.1875 - loss: 4.6392\n",
      "Epoch 10/10\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1120s\u001b[0m 87ms/step - accuracy: 0.1995 - loss: 4.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18854afdac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the text file\n",
    "with open(r\"D:\\HP\\Downloads\\alllines.txt\",'r') as file:\n",
    "    text=file.read()\n",
    "#Tokenize the text\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "#Convert text into sequences of words\n",
    "sequences=tokenizer.texts_to_sequences([text])[0]\n",
    "#Define sequence length\n",
    "sequence_length=5\n",
    "#Data generator class\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self,sequences,batch_size,sequence_length,vocab_size):\n",
    "        self.sequences=sequences\n",
    "        self.batch_size=batch_size\n",
    "        self.sequence_length=sequence_length\n",
    "        self.vocab_size=vocab_size\n",
    "        self.indices=np.arange(sequence_length,len(sequences))\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.indices)/self.batch_size))\n",
    "    def __getitem__(self,index):\n",
    "        batch_indices=self.indices[index * self.batch_size:(index+1) * self.batch_size]\n",
    "        X=np.zeros((self.batch_size,self.sequence_length),dtype=np.int32)\n",
    "        y=np.zeros((self.batch_size,self.vocab_size),dtype=np.float32)\n",
    "        for i,idx in enumerate(batch_indices):\n",
    "            X[i]=self.sequences[idx-self.sequence_length:idx]\n",
    "            y[i,self.sequences[idx]]=1\n",
    "        return X,y\n",
    "\n",
    "vocab_size=len(tokenizer.word_index) + 1 \n",
    "batch_size=64\n",
    "\n",
    "#Instantiate the generator\n",
    "data_gen=DataGenerator(sequences,batch_size=batch_size,sequence_length=sequence_length,vocab_size=vocab_size)\n",
    "\n",
    "#Define the LSTM model\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=100,input_length=sequence_length),\n",
    "    tf.keras.layers.LSTM(150,return_sequences=False),\n",
    "    tf.keras.layers.Dense(vocab_size,activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#Train the model using the generator\n",
    "model.fit(data_gen, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e38bd-9a6c-4602-a285-38a4ca40a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m    1/12831\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:09:39\u001b[0m 2s/step - accuracy: 0.2031 - loss: 3.8731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m930s\u001b[0m 72ms/step - accuracy: 0.3486 - loss: 3.4563\n",
      "Epoch 2/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 73ms/step - accuracy: 0.3576 - loss: 3.3831\n",
      "Epoch 3/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4120s\u001b[0m 321ms/step - accuracy: 0.3621 - loss: 3.3396\n",
      "Epoch 4/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 73ms/step - accuracy: 0.3659 - loss: 3.3140\n",
      "Epoch 5/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m928s\u001b[0m 72ms/step - accuracy: 0.3669 - loss: 3.3054\n",
      "Epoch 6/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m932s\u001b[0m 73ms/step - accuracy: 0.3701 - loss: 3.2806\n",
      "Epoch 7/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m937s\u001b[0m 73ms/step - accuracy: 0.3723 - loss: 3.2690\n",
      "Epoch 8/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 73ms/step - accuracy: 0.3721 - loss: 3.2625\n",
      "Epoch 9/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 73ms/step - accuracy: 0.3732 - loss: 3.2609\n",
      "Epoch 10/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m944s\u001b[0m 74ms/step - accuracy: 0.3737 - loss: 3.2550\n",
      "Epoch 11/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m951s\u001b[0m 74ms/step - accuracy: 0.3750 - loss: 3.2432\n",
      "Epoch 12/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m956s\u001b[0m 74ms/step - accuracy: 0.3765 - loss: 3.2326\n",
      "Epoch 13/20\n",
      "\u001b[1m12831/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m959s\u001b[0m 75ms/step - accuracy: 0.3767 - loss: 3.2259\n",
      "Epoch 14/20\n",
      "\u001b[1m 9996/12831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 75ms/step - accuracy: 0.3830 - loss: 3.1912"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(r\"D:\\HP\\Downloads\\models\\shakespeare_lstm_model.h5\")\n",
    "\n",
    "# Load the saved tokenizer\n",
    "with open(r\"D:\\HP\\Downloads\\models\\tokenizer.pickle\", 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load the text file (Shakespeare plays)\n",
    "with open(r\"D:\\HP\\Downloads\\alllines.txt\", 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize the text\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Data generator class\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, sequences, batch_size, sequence_length, vocab_size):\n",
    "        self.sequences = sequences\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.indices = np.arange(sequence_length, len(sequences))\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.floor(len(self.indices) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get a batch of indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Initialize X and y arrays\n",
    "        X = np.zeros((self.batch_size, self.sequence_length), dtype=np.int32)\n",
    "        y = np.zeros((self.batch_size, self.vocab_size), dtype=np.float32)\n",
    "        \n",
    "        # Generate data for the batch\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            X[i] = self.sequences[idx - self.sequence_length:idx]\n",
    "            y[i, self.sequences[idx]] = 1  # One-hot encoding\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "# Parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Number of unique words\n",
    "batch_size = 64  # Example batch size\n",
    "\n",
    "# Instantiate the generator\n",
    "data_gen = DataGenerator(sequences, batch_size=batch_size, sequence_length=sequence_length, vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the generator\n",
    "model.fit(data_gen, epochs=20)  # Adjust epochs as necessary\n",
    "import pickle\n",
    "\n",
    "# After training the model, save it as a .h5 file\n",
    "model.save(r\"D:\\HP\\Downloads\\models\\shakespeare_lstm_model.keras\")\n",
    "\n",
    "# Save the tokenizer as a pickle file\n",
    "with open(r\"D:\\HP\\Downloads\\models\\tokenizer.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "model.save(r\"D:\\HP\\Downloads\\models\\shakespeare_lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a6d89-f8e3-4656-8879-05af77b6eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, make predictions with the loaded model \n",
    "def predict_next_word(model, tokenizer, seed_text, sequence_length):\n",
    "    tokenized_input = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    padded_input = pad_sequences([tokenized_input], maxlen=sequence_length, padding='pre')\n",
    "    predicted = model.predict(padded_input, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
    "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
    "    return predicted_word\n",
    "\n",
    "# Example usage of prediction\n",
    "seed_text = \"to be or not to be a\"\n",
    "predicted_word = predict_next_word(model, tokenizer, seed_text, sequence_length)\n",
    "print(f\"Next word prediction: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1295f7-960f-4362-abbb-68fa3dc7a3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8d6f5-e6e5-4d0a-8da7-7f104331ab03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
